# -*- coding: utf-8 -*-
"""TCC3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1muuMOSxLnzsn4PruxYSbfgOOYfiWFRNh
"""

# ============================================================
# IMPORTAÇÕES
# ============================================================

!pip install ftfy > /dev/null

import unicodedata
from pathlib import Path

import ftfy
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from scipy.stats import skew

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score,
    f1_score, roc_auc_score
)

sns.set(style="whitegrid")


# ============================================================
# CONFIGURAÇÕES
# ============================================================

BASE_PATH = Path("/content")

FILES = {
    "nacional": BASE_PATH / "analise_nacional.csv",
    "estados": BASE_PATH / "analises_estaduais.csv",
    "regioes": BASE_PATH / "analises_regionais.csv",
    "municipios": BASE_PATH / "analises_municipios.csv",
}

# Variáveis explicativas principais
VARIAVEIS_EXPLICATIVAS = [
    "taxa_reprovacao_ef", "taxa_reprovacao_em",
    "tdi_ef", "tdi_em",
    "had_ef", "had_em",
    "atu_ef", "atu_em",
    "dsu_ef", "dsu_em",
    "afd_ef_grupo_1", "afd_ef_grupo_5",
    "ird_baixa_regularidade", "ird_alta",
    "ied_ef_nivel_1", "ied_ef_nivel_6",
    "icg_nivel_1", "icg_nivel_6",
]

VAR_EF = [v for v in VARIAVEIS_EXPLICATIVAS if v.endswith("_ef")]
VAR_EM = [v for v in VARIAVEIS_EXPLICATIVAS if v.endswith("_em")]
VAR_GERAIS = [
    "ird_baixa_regularidade",
    "ird_alta",
    "afd_ef_grupo_1",
    "afd_ef_grupo_5",
    "icg_nivel_1",
    "icg_nivel_6",
]

# Colunas possíveis para abandono
ALVOS_CONT = {
    "ef": [
        "taxa_abandono_ef",
        "taxa_abandono_ef_total",
        "taxa_abandono_ef_anos_iniciais",
        "taxa_abandono_ef_anos_finais",
        "taxa_abandono_ef_ai_af"
    ],
    "em": [
        "taxa_abandono_em",
        "taxa_abandono_em_total",
        "taxa_abandono_em_anos_iniciais",
        "taxa_abandono_em_anos_finais"
    ]
}

# Nome amigável para análise dos orientadores e leitores
VAR_LABELS = {
    "taxa_reprovacao_ef": "Reprovação (EF)",
    "taxa_reprovacao_em": "Reprovação (EM)",
    "tdi_ef": "Distorção idade-série (EF)",
    "tdi_em": "Distorção idade-série (EM)",
    "had_ef": "Horas aula (EF)",
    "had_em": "Horas aula (EM)",
    "atu_ef": "Alunos por turma (EF)",
    "atu_em": "Alunos por turma (EM)",
    "dsu_ef": "Docentes c/ superior (EF)",
    "dsu_em": "Docentes c/ superior (EM)",
    "afd_ef_grupo_1": "Afast. docente grupo 1",
    "afd_ef_grupo_5": "Afast. docente grupo 5",
    "ird_baixa_regularidade": "Regularidade docente baixa",
    "ird_alta": "Regularidade docente alta",
    "ied_ef_nivel_1": "Esforço docente EF (nível 1)",
    "ied_ef_nivel_6": "Esforço docente EF (nível 6)",
    "icg_nivel_1": "Complexidade gestão (nível 1)",
    "icg_nivel_6": "Complexidade gestão (nível 6)",
}

CENTRO_OESTE_LIST = [
    "divinópolis","formiga","pará de minas","itaúna",
    "bom despacho","oliveira","lagoa da prata","nova serrana",
    "abaeté","bambuí","carmo do cajuru","arcos",
    "piumhi","santo antônio do monte","perdigão","itaguara",
    "camacho","japaraíba","papagaios","são gonçalo do pará"
]


# ============================================================
# FUNÇÕES AUXILIARES
# ============================================================

def nome_amigavel(var):
    return VAR_LABELS.get(var, var)

def corrigir_texto(texto):
    if not isinstance(texto, str):
        return texto
    texto = texto.strip()
    texto = ftfy.fix_text(texto)
    texto = unicodedata.normalize("NFC", texto)
    return texto

def tratar_faltantes_e_outliers(df):
    df = df.copy()
    for col in df.columns:
        if pd.api.types.is_numeric_dtype(df[col]):
            vals = df[col].dropna()
            if vals.empty:
                continue
            q1, q3 = vals.quantile([0.25, 0.75])
            iqr = q3 - q1
            li, ls = q1 - 1.5 * iqr, q3 + 1.5 * iqr
            df[col] = np.clip(df[col], li, ls)
            df[col].fillna(vals.mean(), inplace=True)
        else:
            df[col] = df[col].astype(str).apply(corrigir_texto)
    return df

def carregar_base(path, nome):
    print(f"\n[INFO] Carregando base '{nome}'...")
    df = pd.read_csv(path, sep=";", encoding="utf-8-sig")
    df.columns = [ftfy.fix_text(c.strip().lower()) for c in df.columns]
    df = tratar_faltantes_e_outliers(df)
    print(f"[INFO] {len(df)} linhas carregadas.")
    return df

def filtrar_centro_oeste_mg(df):
    CO_MG_IDS = [
        3122306, 3126109, 3147105, 3133808, 3107406, 3145604, 3137205, 3145208,
        3100203, 3105103, 3114204, 3104205, 3151503, 3160405, 3149705, 3132206,
        3110400, 3135308, 3146909, 3161809
    ]

    dfc = df.copy()

    if "id_municipio" not in dfc.columns:
        print("[ERRO] Coluna 'id_municipio' não encontrada na base.")
        return dfc

    dfc["id_municipio"] = dfc["id_municipio"].astype(int)

    dfc = dfc[dfc["id_municipio"].isin(CO_MG_IDS)]

    return dfc

def encontrar_alvo(df, opcoes):
    for nome in opcoes:
        if nome.lower() in df.columns:
            return nome.lower()
    return None


# ============================================================
# MÉTRICAS (para exibir nos gráficos)
# ============================================================

def gerar_texto_metricas(res):
    return (
        f"Acurácia: {res['accuracy']:.3f}\n"
        f"Recall: {res['recall']:.3f}\n"
        f"Precision: {res['precision']:.3f}\n"
        f"F1-Score: {res['f1']:.3f}\n"
        f"ROC-AUC: {res['roc_auc']:.3f}"
    )


# ============================================================
# PREPARAÇÃO PARA MODELAGEM
# ============================================================

def preparar_dados_classificacao(df, alvo_cont, variaveis):
    if alvo_cont not in df.columns:
        return None, None, None, None, None

    df = df.copy()
    alvo_bin = alvo_cont + "_bin"
    df[alvo_bin] = (df[alvo_cont] > 0).astype(int)

    cols_x = [v for v in variaveis if v in df.columns]
    if not cols_x:
        return None, None, None, None, None

    df_mod = df[cols_x + [alvo_bin]].dropna()

    if df_mod[alvo_bin].nunique() < 2:
        return None, None, None, None, None

    if df_mod[alvo_bin].value_counts().min() < 2:
        return None, None, None, None, None

    X = df_mod[cols_x].values
    y = df_mod[alvo_bin].values

    return X, y, cols_x, df_mod, alvo_bin


# ============================================================
# TREINAMENTO
# ============================================================

def treinar_modelos(X, y):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, stratify=y, random_state=42
    )

    res = {}

    # Logistic Regression
    lr = LogisticRegression(max_iter=1000, class_weight="balanced")
    lr.fit(X_train, y_train)
    y_pred_lr = lr.predict(X_test)
    y_proba_lr = lr.predict_proba(X_test)[:, 1]

    res["logreg"] = {
        "accuracy": accuracy_score(y_test, y_pred_lr),
        "precision": precision_score(y_test, y_pred_lr),
        "recall": recall_score(y_test, y_pred_lr),
        "f1": f1_score(y_test, y_pred_lr),
        "roc_auc": roc_auc_score(y_test, y_proba_lr),
        "modelo": lr
    }

    # Random Forest
    rf = RandomForestClassifier(
        n_estimators=300, random_state=42,
        class_weight="balanced", n_jobs=-1
    )
    rf.fit(X_train, y_train)
    y_pred_rf = rf.predict(X_test)
    y_proba_rf = rf.predict_proba(X_test)[:, 1]

    res["rf"] = {
        "accuracy": accuracy_score(y_test, y_pred_rf),
        "precision": precision_score(y_test, y_pred_rf),
        "recall": recall_score(y_test, y_pred_rf),
        "f1": f1_score(y_test, y_pred_rf),
        "roc_auc": roc_auc_score(y_test, y_proba_rf),
        "modelo": rf,
        "feature_importances": rf.feature_importances_
    }

    return res


# ============================================================
# GRÁFICOS (com métricas)
# ============================================================

def caixa_metricas(res, ax):
    texto = gerar_texto_metricas(res)
    ax.text(
        1.05, 0.95, texto,
        transform=ax.transAxes,
        fontsize=10,
        va="top",
        bbox=dict(boxstyle="round,pad=0.4", fc="#f0f0f0")
    )


def plot_correlacao_heatmap(df, vars_nivel, alvo, titulo, res):
    df_aux = df[[v for v in vars_nivel if v in df.columns] + [alvo]].dropna()
    corr = df_aux.corr()[[alvo]].sort_values(by=alvo, ascending=False)

    fig, ax = plt.subplots(figsize=(7, 0.4 * len(corr) + 2))
    sns.heatmap(
        corr,
        annot=True, cmap="coolwarm", center=0,
        yticklabels=[nome_amigavel(v) for v in corr.index],
        ax=ax
    )
    ax.set_title(f"Correlação — {titulo}")
    caixa_metricas(res["logreg"], ax)  # LogReg como referência
    plt.tight_layout()
    plt.show()


def plot_importancia(cols_x, importancias, titulo, res):
    df_imp = pd.DataFrame({"var": cols_x, "imp": importancias})
    df_imp = df_imp.sort_values("imp", ascending=True)

    fig, ax = plt.subplots(figsize=(8, 0.5 * len(df_imp) + 2))
    sns.barplot(
        x="imp", y=df_imp["var"].apply(nome_amigavel),
        data=df_imp, ax=ax
    )
    ax.set_title(f"Importância das Variáveis — {titulo}")
    caixa_metricas(res["rf"], ax)
    plt.tight_layout()
    plt.show()


def plot_boxplots(df_mod, vars_ord, alvo_bin, titulo, res, top_k=4):
    vars_plot = vars_ord[:top_k]
    df_melt = df_mod[vars_plot + [alvo_bin]].melt(
        id_vars=alvo_bin,
        var_name="variavel",
        value_name="valor"
    )
    fig, ax = plt.subplots(figsize=(10, 5))
    sns.boxplot(
        data=df_melt,
        x="variavel", y="valor",
        hue=alvo_bin,
        showfliers=False,
        ax=ax
    )
    ax.set_title(f"Distribuição — {titulo}")
    caixa_metricas(res["rf"], ax)
    plt.xticks(rotation=40)
    plt.tight_layout()
    plt.show()


# ============================================================
# COMPARAÇÃO BRASIL X CENTRO-OESTE
# ============================================================

def plot_comparacao(df_nac, df_co, alvo_ef, alvo_em):
    ef_br = df_nac[alvo_ef].mean()
    em_br = df_nac[alvo_em].mean()

    ef_co = df_co[alvo_ef].mean()
    em_co = df_co[alvo_em].mean()

    categorias = ["Ensino Fundamental", "Ensino Médio"]
    brasil_vals = [ef_br, em_br]
    co_vals = [ef_co, em_co]

    x = np.arange(len(categorias))
    largura = 0.35

    plt.figure(figsize=(8, 5))
    plt.bar(x - largura/2, brasil_vals, largura, label="Brasil")
    plt.bar(x + largura/2, co_vals, largura, label="Centro-Oeste MG")

    plt.xticks(x, categorias)
    plt.ylabel("Taxa média de abandono (%)")
    plt.title("Brasil x Centro-Oeste MG – Taxa de Abandono (EF/EM)")
    plt.legend()
    plt.tight_layout()
    plt.show()


# ============================================================
# MAIN
# ============================================================


def main():
    bases = {n: carregar_base(p, n) for n, p in FILES.items()}
    bases["centro_oeste_mg"] = filtrar_centro_oeste_mg(bases["municipios"])

    # LOOP PRINCIPAL
    for nome, df in bases.items():
        print(f"\n======= BASE: {nome.upper()} =======")

        for nivel in ["ef", "em"]:
            alvo = encontrar_alvo(df, ALVOS_CONT[nivel])
            if alvo is None:
                continue

            vars_nivel = VAR_EF + VAR_GERAIS if nivel == "ef" else VAR_EM + VAR_GERAIS
            titulo = f"{nome.upper()} – {nivel.upper()}"

            X, y, cols_x, df_mod, alvo_bin = preparar_dados_classificacao(df, alvo, vars_nivel)
            if X is None:
                continue

            resultados = treinar_modelos(X, y)

            # 1) Heatmap
            plot_correlacao_heatmap(df, vars_nivel, alvo, titulo, resultados)

            # 2) Importância
            plot_importancia(cols_x, resultados["rf"]["feature_importances"], titulo, resultados)

            # 3) Boxplot
            imp = resultados["rf"]["feature_importances"]
            vars_ord = [x for _, x in sorted(zip(imp, cols_x), reverse=True)]
            plot_boxplots(df_mod, vars_ord, alvo_bin, titulo, resultados)

    # Comparação final
    alvo_ef = encontrar_alvo(bases["nacional"], ALVOS_CONT["ef"])
    alvo_em = encontrar_alvo(bases["nacional"], ALVOS_CONT["em"])

    if alvo_ef and alvo_em:
        plot_comparacao(
            bases["nacional"],
            bases["centro_oeste_mg"],
            alvo_ef,
            alvo_em
        )

# Execução
main()